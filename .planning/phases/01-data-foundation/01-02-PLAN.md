---
phase: 01-data-foundation
plan: 02
type: execute
wave: 2
depends_on:
  - 01-01
files_modified:
  - src/ensemble/contamination.py
  - src/ensemble/cli.py
  - tests/test_contamination.py
autonomous: true
requirements:
  - DATA-03

must_haves:
  truths:
    - "Running `python -m ensemble contamination-check data/sample/sample_events.json` queries the LLM for each event and reports contamination status"
    - "Events where the model knows the outcome with high confidence are flagged EXCLUDE"
    - "Events where the model does not know the outcome are marked INCLUDE"
    - "Contamination check never reveals the actual outcome to the model"
  artifacts:
    - path: "src/ensemble/contamination.py"
      provides: "Contamination check prompt, scoring logic, batch check runner"
      exports: ["check_contamination", "score_contamination", "ContaminationResult"]
    - path: "tests/test_contamination.py"
      provides: "Scoring logic tests and prompt construction tests"
  key_links:
    - from: "src/ensemble/contamination.py"
      to: "src/ensemble/models.py"
      via: "Uses Event model to extract title, question, category, close_time for prompt"
      pattern: "event\\.(title|question|category)"
    - from: "src/ensemble/cli.py"
      to: "src/ensemble/contamination.py"
      via: "contamination-check command calls check_contamination()"
      pattern: "check_contamination"
---

<objective>
Implement the contamination detection system that probes whether gpt-5-nano knows the outcome of benchmark events, preventing training data leakage from invalidating the experiment.

Purpose: DATA-03 requires a contamination check that queries the model to determine if it already knows an event's outcome. This is critical for benchmark validity -- if the model knows outcomes from training data, persona bias effects cannot be isolated.
Output: Working `python -m ensemble contamination-check <file>` command that checks each event and reports INCLUDE/FLAG/EXCLUDE status.
</objective>

<execution_context>
@/home/sohamchoulwar/.claude/get-shit-done/workflows/execute-plan.md
@/home/sohamchoulwar/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-foundation/01-RESEARCH.md
@.planning/phases/01-data-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Contamination check module with prompt and scoring</name>
  <files>
    src/ensemble/contamination.py
    tests/test_contamination.py
  </files>
  <action>
    1. Create src/ensemble/contamination.py:

       Define `ContaminationResult(BaseModel)`:
       - knows_outcome: bool
       - confidence: Literal["high", "medium", "low", "none"]
       - stated_outcome: str | None
       - reasoning: str
       - verdict: Literal["INCLUDE", "FLAG", "EXCLUDE"] (computed property or set by scoring)

       Define constants:
       - CONTAMINATION_CHECK_SYSTEM: System prompt from research (the "You are a research assistant helping detect training data contamination..." prompt). Emphasize honesty and scientific integrity.
       - CONTAMINATION_CHECK_USER: Template string with {title}, {question}, {category}, {close_date} placeholders.

       Implement `score_contamination(result: ContaminationResult) -> str`:
       - knows_outcome=True AND confidence="high" -> "EXCLUDE"
       - knows_outcome=True AND confidence="medium" -> "FLAG"
       - knows_outcome=False OR confidence in ("low", "none") -> "INCLUDE"

       Implement `async def check_contamination(event: Event, model: str = "gpt-5-nano") -> ContaminationResult`:
       - Build user message from CONTAMINATION_CHECK_USER template using event.title, event.question, event.category, event.close_time.strftime("%Y-%m-%d")
       - Call OpenAI API using AsyncOpenAI client with structured output (response_format=ContaminationResult)
       - Load API key from environment (OPENAI_API_KEY via python-dotenv)
       - Set temperature=0 for reproducibility
       - Return the parsed ContaminationResult with verdict set by score_contamination()
       - Handle API errors gracefully: on failure, return a result with knows_outcome=False, confidence="none", reasoning="API call failed: {error}", verdict="FLAG"

       Implement `async def check_all_events(events: list[Event], model: str = "gpt-5-nano") -> list[tuple[Event, ContaminationResult]]`:
       - Run contamination checks sequentially (not parallel -- single LLM call per event, rate limit friendly)
       - Add 1-second delay between calls (asyncio.sleep(1))
       - Return list of (event, result) tuples

    2. Create tests/test_contamination.py:
       - test_score_contamination_exclude: knows_outcome=True + confidence="high" -> "EXCLUDE"
       - test_score_contamination_flag: knows_outcome=True + confidence="medium" -> "FLAG"
       - test_score_contamination_include_low: knows_outcome=True + confidence="low" -> "INCLUDE"
       - test_score_contamination_include_false: knows_outcome=False + confidence="high" -> "INCLUDE"
       - test_score_contamination_include_none: confidence="none" -> "INCLUDE"
       - test_contamination_prompt_excludes_outcome: Verify that CONTAMINATION_CHECK_USER template does NOT contain "outcome", "result", or "settlement" strings
       - test_contamination_prompt_includes_required_fields: Verify template contains {title}, {question}, {category}, {close_date} placeholders
       - Note: Do NOT test the actual API call (requires real API key). Only test scoring logic and prompt construction.

    3. Run `uv run pytest tests/test_contamination.py -v` and confirm all tests pass.
  </action>
  <verify>
    `uv run pytest tests/test_contamination.py -v` -- all scoring and prompt tests pass.
    `uv run python -c "from ensemble.contamination import check_contamination, score_contamination, ContaminationResult; print('imports OK')"` -- prints "imports OK".
  </verify>
  <done>
    Contamination check module exists with prompt template, scoring logic, and async check function. Scoring correctly classifies high-confidence knowledge as EXCLUDE, medium as FLAG, and low/none as INCLUDE. Prompt never reveals outcome to the model.
  </done>
</task>

<task type="auto">
  <name>Task 2: CLI contamination-check command with rich output</name>
  <files>
    src/ensemble/cli.py
  </files>
  <action>
    1. Add `contamination-check` command to src/ensemble/cli.py:
       - Takes `events_file: Path` argument (path to events JSON)
       - Takes `--model` option (default: "gpt-5-nano")
       - Takes `--dry-run` flag that shows which events would be checked without calling the API
       - Loads events using `load_events(events_file)`
       - If not dry-run: runs `check_all_events(events, model)` using asyncio.run()
       - Prints results in a rich Table with columns: event_ticker, title (truncated to 40 chars), verdict (colored: green=INCLUDE, yellow=FLAG, red=EXCLUDE), confidence, stated_outcome
       - Prints summary: "N events checked: X INCLUDE, Y FLAG, Z EXCLUDE"
       - If dry-run: prints list of event tickers that would be checked

    2. Ensure the CLI still works for the existing `load` command (don't break it).

    3. Test manually:
       - `uv run python -m ensemble contamination-check data/sample/sample_events.json --dry-run` should list 2 event tickers
       - `uv run python -m ensemble --help` should show both `load` and `contamination-check` commands
  </action>
  <verify>
    `uv run python -m ensemble contamination-check data/sample/sample_events.json --dry-run` -- lists event tickers without calling API.
    `uv run python -m ensemble --help` -- shows both `load` and `contamination-check` commands.
    `uv run python -m ensemble load data/sample/sample_events.json` -- still works (no regression).
    `uv run pytest tests/ -v` -- all tests pass.
  </verify>
  <done>
    CLI has `contamination-check` command that loads events, checks each against gpt-5-nano, and displays colored verdict table. Dry-run mode works without API key. Both CLI commands functional.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/ -v` -- all tests pass (models + slicer + contamination scoring)
2. `uv run python -m ensemble contamination-check data/sample/sample_events.json --dry-run` -- lists events without API call
3. `uv run python -m ensemble --help` -- shows load and contamination-check commands
4. Contamination prompt does not contain outcome/result/settlement words (verified by test)
</verification>

<success_criteria>
- Contamination check module scores model knowledge correctly (INCLUDE/FLAG/EXCLUDE)
- Prompt probes model knowledge without revealing actual outcomes
- CLI contamination-check command works with --dry-run and --model options
- Rich table output shows colored verdicts per event
- All existing tests still pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-foundation/01-02-SUMMARY.md`
</output>
